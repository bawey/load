#include "fedMasks.epl"
#include "deadtimeAndBackpressure.epl"
#include "level1TriggerRate.epl"
#include "subsystemsStateChanges.epl"
#include "runStartStop.epl"
#include "fedFractions.epl"

/** STRUCTURE **/
@Description('')
create variable long deadRateTimeout=10000;


@Description('Window to store the oldest and newest from a series of zero-rate events')
create window L1ZeroRates.win:expr(newest_event.rate=0 and (oldest_event.timestamp = timestamp or newest_event.timestamp = timestamp)) as select * from L1Rates;
@Description('Window to hold the most recent value of time measured while rate is stuck at 0')
create window ZeroRateTimer.win:length(1) as (elapsed long);

@Description('Stream for the current number bxNumbers clusters. Might contain series of identical values')
create objectarray schema BxnClustersCountStream as (clusters long, timestamp long, fetchstamp long);
@Description('A window holding the current value of bxNumbers clusters count. Not supposed to accept two subsequent events with the same value.')
create window BxnClustersCount.std:lastevent() as select * from BxnClustersCountStream;

@Description('Same as BxnClustersCountStream, but for trg')
create objectarray schema TrgClustersCountStream as (clusters long, timestamp long, fetchstamp long);
@Description('Same as BxnClustersCount, but for trg')
create window TrgClustersCount.std:lastevent() as select * from TrgClustersCountStream;

/** Streams to broadcast the 'StuckAtRate0'/'RateFine' states information **/
create objectarray schema RateStuckAtZeroEvent as (engineTimestamp long);
create objectarray schema RateFineEvent as (engineTimestamp long);


/** LOGIC **/


insert into RateStuckAtZeroEvent select timestamp as engineTimestamp from ZeroRateTimer match_recognize(
	measures current_timestamp() as timestamp
	pattern (A)
	define A as A.elapsed>deadRateTimeout and (prev(A.elapsed) is null or prev(A.elapsed)<=deadRateTimeout)
);

insert into RateFineEvent select timestamp as engineTimestamp from ZeroRateTimer match_recognize(
	measures current_timestamp() as timestamp
	pattern (A)
	define A as A.elapsed<=deadRateTimeout and (prev(A.elapsed) is null or prev(A.elapsed)>=deadRateTimeout)
);


@Description('Insert all the rates into L1ZeroRates. Retention policy does the trick')
insert into L1ZeroRates select distinct * from L1Rates;

@Name('PopulateZeroRateTimer')
@Watched(label='deadRateElapsed')
@Description('On each update on L1ZeroRates, update the measurement of time spent with rates stuck at 0 ')
insert into ZeroRateTimer select (case when count(*)>1 then max(timestamp)-min(timestamp) else 0 end) as elapsed 
	from pattern[every L1Rates] unidirectional, L1ZeroRates;


/** PART OF LOGIC RELATED TO BxMisalignment **/

/** Count current number of BXNumber values. Insert -1 if the count makes no sense and filter out any identical values directly following each other **/

@Name('BxnClustersCounting')
@Description('Update bxClusters count upon ZeroRateTimer update')
insert into BxnClustersCountStream select count(distinct ctl.bxNumber) as clusters, max(ctl.timestamp.getTime()) as timestamp, max(ctl.fetchstamp) as fetchstamp
	from pattern[every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional, FrlCtlLnk.std:unique(fedId) as ctl;

@Description('Allow only the first event into the window and each subsequent')
insert into BxnClustersCount select clusters, fetchstamp, timestamp from BxnClustersCountStream match_recognize(
	measures A.clusters as clusters, A.fetchstamp as fetchstamp, A.timestamp as timestamp
	pattern (A)	
	define A as prev(A.clusters, 1) is null or A.clusters != prev(A.clusters, 1) 
);

@Description('As the rate rises back, insert -1 to indicate pointlessness of analysis')
insert into BxnClustersCountStream select -1l as clusters, null as fetchstamp, timestamp as timestamp from L1Rates match_recognize(
	measures A.timestamp as timestamp
	pattern (A B)
	define A as A.rate = 0, B as B.rate >0
);

/** Same counting as for BXNumbers, but for Trigger Number. **/

insert into TrgClustersCountStream select distinct count(distinct ctl.triggerNumber) as clusters, max(ctl.timestamp.getTime()) as timestamp, max(ctl.fetchstamp) as fetchstamp
	from pattern[every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional, FrlCtlLnk.std:unique(fedId) as ctl;

@Verbose(label='TrgClustersCount')
insert into TrgClustersCount select clusters, fetchstamp, timestamp from TrgClustersCountStream match_recognize(
	measures A.clusters as clusters, A.fetchstamp as fetchstamp, A.timestamp as timestamp
	pattern (A)	
	define A as prev(A.clusters, 1) is null or A.clusters != prev(A.clusters, 1) 
);

insert into TrgClustersCountStream select -1l as clusters, null as fetchstamp, timestamp as timestamp from BxnClustersCountStream(clusters=-1);


/** PART OF LOGIC RELATED TO TrgMisalignment **/


/** OUTPUTS **/


@Name('bxnMisalignment.headline')
@Priority(10)
@Verbose(label='bxoutput', extraNfo='bxNumbers misaligned', fields={'bxn.fetchstamp','bxn.timestamp','bxn.clusters'})
select bxn.clusters, bxn.fetchstamp, bxn.timestamp from pattern [every bxn=BxnClustersCount(clusters>1)];

@Name('bxNumber misalignment - details')
@Priority(1)
@Verbose(label='bxoutput', fields={'time','fetchtime', 'bxNumber','support','seenFedIds'})
select bxNumber, window(ctl.*).aggregate("", (result, row) => result||" "||row.fedId.toString() ) as seenFedIds, count(fedId) as support, 
	date(max(fetchstamp)) as fetchtime, date(max(timestamp.getTime())) as time
	from pattern[every BxnClustersCount(clusters>1)]  unidirectional, FrlCtlLnk.std:unique(fedId) as ctl group by bxNumber order by count(fedId) desc;


@Verbose(label='bxoutput', extraNfo='Bx misalignment problem gone', fields={'time', 'fetchtime'})
select fetchtime, time from BxnClustersCount match_recognize(
	measures B.clusters as clusters, date(B.fetchstamp) as fetchtime, date(B.timestamp) as time
	pattern (B)
	define B as B.clusters<=1 and prev(B.clusters,1)>1
);

@Watched(label='bxnClustersCount')
select clusters from BxnClustersCountStream;



@Priority(10)
@Verbose(label='trgoutput', extraNfo='trgNumbers misaligned', fields={'trg.fetchstamp','trg.timestamp','trg.clusters'})
select trg.clusters, trg.fetchstamp, trg.timestamp from pattern [every trg=TrgClustersCount(clusters>1)];


@Priority(1)
@Verbose(label='trgoutput', fields={'time','fetchtime', 'triggerNumber','support','seenFedIds'})
select triggerNumber, window(ctl.*).aggregate("", (result, row) => result||" "||row.fedId.toString() ) as seenFedIds, count(fedId) as support, 
	date(max(fetchstamp)) as fetchtime, date(max(timestamp.getTime())) as time
	from pattern[every TrgClustersCount(clusters>1)]  unidirectional, FrlCtlLnk.std:unique(fedId) as ctl group by triggerNumber order by count(fedId) desc;


@Verbose(label='trgoutput', extraNfo='Trg misalignment problem gone', fields={'time', 'fetchtime'})
select date(fetchstamp) as fetchtime, date(timestamp) as time from TrgClustersCount match_recognize(
	measures B.clusters as clusters, B.fetchstamp as fetchstamp, B.timestamp as timestamp
	pattern (B)
	define B as B.clusters<=1 and prev(B.clusters,1)>1
);

@Watched(label='trgClustersCount')
select clusters from TrgClustersCountStream;



/** A MESSY PART FOR RESYNC NUMBER CHECKING **/

create window FedResyncInfo.std:unique(fedId) as (fedId int, myrinetLastResyncEvt long, myrinetResync long);

@Description('When rate has been zero for long enough, count the clusters of myrinetLastResyncEvt values')
@Priority(10)
insert into FedResyncInfo 
select lnk.fedId as fedId, crd.myrinetLastResyncEvt as myrinetLastResyncEvt, crd.myrinetResync as myrinetResync from 
	pattern[every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional,
	frlcontrollerCard.std:unique(context, slotNumber) as crd, FrlCtlLnk.std:unique(fedId) as lnk
		where lnk.context = crd.context and lnk.slotNumber = crd.slotNumber;


@Verbose(label="output", fields={'time','support','myrinetLastResyncEvt','details'}, extraNfo="myrinetLastResyncEvt discrepancy" )
@Priority(8)
select date(current_timestamp()) as time, count(fedId) as support, myrinetLastResyncEvt, 
	window(x.*).aggregate("", (result, row) => result||row.fedId.toString()||" ") as details
	from pattern[every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional, 
	FedResyncInfo as x where (select count(distinct myrinetLastResyncEvt) from FedResyncInfo)>1 group by myrinetLastResyncEvt
	order by count(fedId) desc;


@Verbose(label="output", fields={'time','support','myrinetResync','details'}, extraNfo="myrinetResync discrepancy")
@Priority(8)
select date(current_timestamp()) as time, count(fedId) as support, myrinetResync, 
	window(x.*).aggregate("", (result, row) => result||row.fedId.toString()||" ") as details
	from pattern[every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional, 
	FedResyncInfo as x where (select count(distinct myrinetResync) from FedResyncInfo)>1 group by myrinetResync
	order by count(fedId) desc;


@Watched(label='distinctMyrinetR')
select count(distinct myrinetLastResyncEvt) from FedResyncInfo;

@Watched(label='distinctMyrinetR')
select count(distinct myrinetResync) from FedResyncInfo;

/** ANOTHER MESSY CHUNK - FEDS STUCK @ ERROR, WARNING etc AND  **/

@Verbose(label='output-devel', fields={'time','b.fedId','b.bpFraction'}, extraNfo='FED stuck with Backpressure at zero rate')
select b.fedId, date(b.timestamp) as time, b.bpFraction from pattern [every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional, FrlBackpressure as b;

@Verbose(label='output-devel', fields={'time','b.fedId','b.dtFraction'}, extraNfo='FED stuck with Deadtime at zero rate')
select b.fedId, date(b.timestamp) as time, b.dtFraction from pattern [every ZeroRateTimer(elapsed>deadRateTimeout)] unidirectional, FmmDeadtime as b;

/** feds stuck in sth else than ready **/

@Name("stuckFeds")
@Verbose(label="output", fields={'timestamp','fedId', 'dOos','dBusy','dWarning','dError','dIllegal', 'dTime'}, extraNfo='FED stuck')
select timestamp, fedId, dTime, dTime-(dBusy+dWarning+dError+dOos+dReady) as dIllegal, dWarning, dError, dOos, dBusy from FedFractions
where dTime>0 and (dBusy=dTime or dWarning=dTime or dError = dTime or dOos = dTime or (dBusy+dWarning+dError+dOos+dReady)=0);


/** STATEMENTS TOGGLING: would be cool to write insert from ('A','B','C') etc. Possible?**/

@Verbose(label='debug', extraNfo='SuspendingStatement', fields={'name'})
insert into SuspendedStatements select 'bxnMisalignment.headline' as name from pattern[every RunStop];

@Verbose(label='debug', extraNfo='ResumingStatement', fields={'name'})
on pattern[every RunStart] delete from SuspendedStatements where name="bxnMisalignment.headline";

@Verbose(label='debug', extraNfo='SuspendingStatement', fields={'name'})
insert into SuspendedStatements select 'stuckFeds' as name from pattern[every RateStuckAtZeroEvent];

@Verbose(label='debug', extraNfo='ResumingStatement', fields={'name'})
on pattern[every RateFineEvent] delete from SuspendedStatements where name="stuckFeds";

@Verbose(label='debug', extraNfo='SuspendingStatement', fields={'name'})
insert into SuspendedStatements select 'PopulateZeroRateTimer' as name from pattern[every RunStop];

@Verbose(label='debug', extraNfo='ResumingStatement', fields={'name'})
on pattern[every RunStart] delete from SuspendedStatements where name="PopulateZeroRateTimer";

